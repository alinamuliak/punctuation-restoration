{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing of data\n",
    "\n",
    "Here I will aim to form an array of arrays of tuples with each word and the following punctuation mark.\n",
    "\n",
    "Example of single sentence:\n",
    "[('I', 'SPACE'),\n",
    "('love', 'SPACE'),\n",
    "('kittens', 'COMMA'),\n",
    "('and', 'SPACE').\n",
    "('you', 'QUESTIONMARK')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "datapath = 'target-sentences-tokenized'\n",
    "onlyfiles = [join(datapath, f) for f in listdir(datapath) if isfile(join(datapath, f))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = []\n",
    "punctuations = {',', '.', '!', '?'}\n",
    "ignore = {'\"', \"'\", '-', '–', '—', ':', ';'}\n",
    "for file in onlyfiles:\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        curr_sent = []\n",
    "        i = 0\n",
    "        while i < len(words) - 1:\n",
    "            current_pair = [words[i].lower()]\n",
    "            if words[i].isnumeric():\n",
    "                current_pair = ['NUM']\n",
    "            if words[i] in ignore:\n",
    "                i += 1\n",
    "                continue\n",
    "            if words[i + 1] in punctuations:\n",
    "                current_pair.append(words[i + 1])\n",
    "                i += 1\n",
    "            elif words[i + 1] in ignore:\n",
    "                current_pair.append(' ')\n",
    "                i += 1\n",
    "            else:\n",
    "                current_pair.append(' ')\n",
    "            curr_sent.append(tuple(current_pair))\n",
    "            i += 1\n",
    "        data.append(curr_sent)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[[('я', ' '),\n  ('високий', ','),\n  ('з', ' '),\n  ('чорною', ' '),\n  ('бородою', ' '),\n  ('й', ' '),\n  ('ненавиджу', ' '),\n  ('публічність', '.')],\n [('я', ' '),\n  ('не', ' '),\n  ('маю', ' '),\n  ('взагалі', ' '),\n  ('грошей', ','),\n  ('не', ' '),\n  ('люблю', ' '),\n  ('вівсянку', ','),\n  ('а', ' '),\n  ('єдине', ' '),\n  ('прагнення', ' '),\n  ('мого', ' '),\n  ('життя', ' '),\n  ('померти', ' '),\n  ('в', ' '),\n  ('достатку', '.')],\n [('ставлення', ' '),\n  ('до', ' '),\n  ('інших', ' '),\n  ('холодне', ' '),\n  ('й', ' '),\n  ('безсердечне', '.')],\n [('я', ' '),\n  ('не', ' '),\n  ('піклуюсь', ' '),\n  ('про', ' '),\n  ('моїх', ' '),\n  ('колег', ','),\n  ('а', ' '),\n  ('також', ' '),\n  ('я', ' '),\n  ('ще', ' '),\n  ('не', ' '),\n  ('дав', ' '),\n  ('жодної', ' '),\n  ('копійки', ' '),\n  ('жебраку', ' '),\n  ('чи', ' '),\n  ('на', ' '),\n  ('милостиню', '.')],\n [('що', ' '),\n  ('ж', ','),\n  ('мій', ' '),\n  ('любий', ' '),\n  ('лікарю', ','),\n  ('се', ' '),\n  ('справжній', ' '),\n  ('опис', ' '),\n  ('мене', ','),\n  ('людини', ','),\n  ('за', ' '),\n  ('якою', ' '),\n  ('полював', ' '),\n  ('той', ' '),\n  ('детектив', '.')],\n [('ви', ','),\n  ('знайомі', ' '),\n  ('зі', ' '),\n  ('нещодавнім', ' '),\n  ('дієписом', ' '),\n  ('злочинів', ' '),\n  ('у', ' '),\n  ('нью-йорку', ','),\n  ('повинні', ' '),\n  ('передбачити', ' '),\n  ('наслідок', '.')],\n [('коли', ' '),\n  ('я', ' '),\n  ('пообіцяв', ' '),\n  ('вам', ' '),\n  ('показати', ' '),\n  ('вашому', ' '),\n  ('надзвичайному', ' '),\n  ('зору', ' '),\n  ('того', ','),\n  ('хто', ' '),\n  ('переслідував', ' '),\n  ('мене', ','),\n  ('ви', ' '),\n  ('були', ' '),\n  ('засміялись', ' '),\n  ('з', ' '),\n  ('мене', ','),\n  ('бо', ' '),\n  ('сказали', ','),\n  ('що', ' '),\n  ('слідці', ' '),\n  ('й', ' '),\n  ('убивці', ' '),\n  ('ніколи', ' '),\n  ('не', ' '),\n  ('зустрічаються', ' '),\n  ('одне', ' '),\n  ('з', ' '),\n  ('одним', ' '),\n  ('в', ' '),\n  ('нью-йорку', '.')],\n [('я', ' '),\n  ('ж', ' '),\n  ('вам', ' '),\n  ('показав', ','),\n  ('що', ' '),\n  ('се', ' '),\n  ('таки', ' '),\n  ('можливо', '.')],\n [('він', ' '),\n  ('не', ' '),\n  ('намагався', ' '),\n  ('заснути', ','),\n  ('а', ' '),\n  ('сидів', ' '),\n  ('у', ' '),\n  ('ліжку', ','),\n  ('обнявши', ' '),\n  ('руками', ' '),\n  ('коліна', ','),\n  ('і', ' '),\n  ('думав', '.')],\n [('думка', ' '),\n  ('про', ' '),\n  ('іспит', ' '),\n  ('була', ' '),\n  ('йому', ' '),\n  ('противна', '.')]]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "29760"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319254\n",
      "35346\n"
     ]
    }
   ],
   "source": [
    "# split data into training and validation set in the ratio 90:10\n",
    "train_set, test_set = train_test_split(data, train_size=0.9, test_size=0.1, random_state=101)\n",
    "\n",
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[('щось', ' '),\n ('схоже', ' '),\n ('стосується', ' '),\n ('й', ' '),\n ('перекладу', '.')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some tagged words.\n",
    "train_tagged_words[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'!', ',', ' ', '?', '.'}\n"
     ]
    }
   ],
   "source": [
    "#use set datatype to check how many unique tags are present in training data\n",
    "tags = {tag for word, tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)\n",
    "\n",
    "# check total words in vocabulary\n",
    "vocab = {word for word, tag in train_tagged_words}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01500259 0.09622349 0.8556648  0.00206932 0.0305225 ]\n",
      " [0.00537951 0.0825138  0.8946513  0.00319408 0.0142613 ]\n",
      " [0.00559264 0.11710528 0.7946261  0.00704974 0.07562622]\n",
      " [0.01344861 0.08981749 0.8650336  0.00576369 0.0259366 ]\n",
      " [0.01138602 0.09963968 0.8527504  0.00614941 0.03007447]]\n"
     ]
    }
   ],
   "source": [
    "# compute Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "#now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "\n",
    "\n",
    "    return (count_w_given_tag, count_tag)\n",
    "\n",
    "# compute  Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)\n",
    "\n",
    "# creating t x t transition matrix of tags, t= no of tags\n",
    "# Matrix(i, j) represents P(jth tag after the ith tag)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "\n",
    "print(tags_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "          !         ,                   ?         .\n!  0.015003  0.096223  0.855665  0.002069  0.030523\n,  0.005380  0.082514  0.894651  0.003194  0.014261\n   0.005593  0.117105  0.794626  0.007050  0.075626\n?  0.013449  0.089817  0.865034  0.005764  0.025937\n.  0.011386  0.099640  0.852750  0.006149  0.030074",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>!</th>\n      <th>,</th>\n      <th></th>\n      <th>?</th>\n      <th>.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>!</th>\n      <td>0.015003</td>\n      <td>0.096223</td>\n      <td>0.855665</td>\n      <td>0.002069</td>\n      <td>0.030523</td>\n    </tr>\n    <tr>\n      <th>,</th>\n      <td>0.005380</td>\n      <td>0.082514</td>\n      <td>0.894651</td>\n      <td>0.003194</td>\n      <td>0.014261</td>\n    </tr>\n    <tr>\n      <th></th>\n      <td>0.005593</td>\n      <td>0.117105</td>\n      <td>0.794626</td>\n      <td>0.007050</td>\n      <td>0.075626</td>\n    </tr>\n    <tr>\n      <th>?</th>\n      <td>0.013449</td>\n      <td>0.089817</td>\n      <td>0.865034</td>\n      <td>0.005764</td>\n      <td>0.025937</td>\n    </tr>\n    <tr>\n      <th>.</th>\n      <td>0.011386</td>\n      <td>0.099640</td>\n      <td>0.852750</td>\n      <td>0.006149</td>\n      <td>0.030074</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "# the table is same as the transition table shown in section 3 of article\n",
    "tags_df = pd.DataFrame(tags_matrix, columns=list(tags), index=list(tags))\n",
    "display(tags_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "\n",
    "    for key, word in enumerate(words):\n",
    "        # initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag] + tags_df.loc['?', tag] + tags_df.loc['!', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  14.385432004928589\n",
      "Viterbi Algorithm Accuracy:  69.92481203007519\n"
     ]
    }
   ],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    "\n",
    "# choose random 10 numbers\n",
    "rndom = [random.randint(1, len(test_set)) for x in range(10)]\n",
    "\n",
    "# list of 10 sents on which we test the model\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "\n",
    "# Here We will only test 10 sentences to check the accuracy\n",
    "# as testing the whole training set takes huge amount of time\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ', accuracy * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[('щодо', ' '),\n ('дсту', '!'),\n ('дуже', ' '),\n ('важко', ' '),\n ('його', ' '),\n ('притягти', ' '),\n ('до', ' '),\n ('цієї', ' '),\n ('статті', ' '),\n ('член', ' '),\n ('правління', ' '),\n ('пятнажко', '!'),\n ('запитав', ' '),\n ('у', ' '),\n ('сидячого', '!'),\n ('прибулий', ' '),\n ('NUM', ' '),\n ('тепер', ' '),\n ('ще', ' '),\n ('декілька', ' '),\n ('разів', ' '),\n ('повторіть', '.'),\n ('свою', ' '),\n ('брехню', ','),\n ('про', ' '),\n ('відсутність', ' '),\n ('цього', ' '),\n ('набряку', '!'),\n ('у', ' '),\n ('моєму', ' '),\n ('лівому', '!'),\n ('боці', ' '),\n ('і', ' '),\n ('думаю', ','),\n ('я', ' '),\n ('можу', ' '),\n ('вважатись', '!'),\n ('вилікуваним', '!'),\n ('щоб', ' '),\n ('ласувати', '!'),\n ('сосисками', ','),\n ('і', ' '),\n ('гречаними', '!'),\n ('тортами', '!'),\n ('»', ' '),\n ('у', ' '),\n ('цьому', ' '),\n ('підвалі', ' '),\n ('вже', ' '),\n ('давно', ' '),\n ('живе', ' '),\n ('інша', ' '),\n ('людина', ' '),\n ('і', ' '),\n ('взагалі', ' '),\n ('не', ' '),\n ('буває', ' '),\n ('так', ' '),\n ('щоб', ' '),\n ('усе', ' '),\n ('стало', ' '),\n ('як', ' '),\n ('було', ' '),\n ('він', ' '),\n ('доклав', ','),\n ('щоку', ' '),\n ('до', ' '),\n ('голови', ' '),\n ('своєї', ' '),\n ('подруги', ','),\n ('обняв', '!'),\n ('маргариту', ' '),\n ('і', ' '),\n ('став', ' '),\n ('бурмотіти', ' '),\n ('бідна', ' '),\n ('бідна', ' '),\n ('але', ' '),\n ('це', ' '),\n ('приходить', ' '),\n ('із', ' '),\n ('часом', ' '),\n ('●', ' '),\n ('з', ' '),\n ('метою', ' '),\n ('визначення', ' '),\n ('подальших', ' '),\n ('дій', ' '),\n ('соціологів', '!'),\n ('було', ' '),\n ('організовано', ' '),\n ('чому', ' '),\n ('аня', ' '),\n ('вибрала', ' '),\n ('саме', ' '),\n ('це', ' '),\n ('місце', ' '),\n ('різниця', ' '),\n ('в', ' '),\n ('тому', ' '),\n ('що', ' '),\n ('дитина', ' '),\n ('хоче', ' '),\n ('якомога', ' '),\n ('швидше', ' '),\n ('стати', ' '),\n ('старшою', '!'),\n ('а', ' '),\n ('дорослі', ','),\n ('навпаки', ','),\n ('часто', ' '),\n ('зневажають', '!'),\n ('інфантильність', '!'),\n ('їсти', ' '),\n ('камамбер', '!'),\n ('із', ' '),\n ('рожевим', '.'),\n ('вином', ' '),\n ('на', ' '),\n ('березі', ' '),\n ('сени', '!'),\n ('гуляти', ' '),\n ('крученими', '!'),\n ('вуличками', ' '),\n ('монмартра', '!'),\n ('й', ' '),\n ('дивитися', ' '),\n ('на', ' '),\n ('єлисейські', '!'),\n ('поля', ' '),\n ('з', ' '),\n ('тріумфальної', '!'),\n ('арки', '!')]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_seq"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing\n"
     ]
    }
   ],
   "source": [
    "# Code to test all the test sentences\n",
    "# (takes alot of time to run s0 we won't run it here)\n",
    "# tagging the test sentences()\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "test_untagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "\n",
    "\n",
    "print('Starting testing')\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_untagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(test_tagged_words, test_untagged_words) if i == j]\n",
    "\n",
    "accuracy = len(check) / len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ', accuracy * 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
