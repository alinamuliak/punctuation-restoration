{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of data\n",
    "\n",
    "Here I will aim to form an array of arrays of tuples with each word and the following punctuation mark.\n",
    "\n",
    "Example of single sentence:\n",
    "[('I', ' '),\n",
    "('love', ' '),\n",
    "('kittens', ','),\n",
    "('and', ' ').\n",
    "('you', '?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "datapath = 'target-sentences-tokenized'\n",
    "onlyfiles = [join(datapath, f) for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "punctuations = {',', '.', '!', '?'}\n",
    "ignore = {'\"', \"'\", '-', '–', '—', ':', ';'}\n",
    "for file in onlyfiles:\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for l in lines:\n",
    "        words = l.split()\n",
    "        curr_sent = []\n",
    "        i = 0\n",
    "        while i < len(words) - 1:\n",
    "            current_pair = [words[i].lower()]\n",
    "            if words[i].isnumeric():\n",
    "                current_pair = ['NUM']\n",
    "            if words[i] in ignore:\n",
    "                i += 1\n",
    "                continue\n",
    "            if words[i + 1] in punctuations:\n",
    "                current_pair.append(words[i + 1])\n",
    "                i += 1\n",
    "            elif words[i + 1] in ignore:\n",
    "                current_pair.append(' ')\n",
    "                i += 1\n",
    "            else:\n",
    "                current_pair.append(' ')\n",
    "            curr_sent.append(tuple(current_pair))\n",
    "            i += 1\n",
    "        data.append(curr_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('вона', ' '),\n",
       "  ('влаштувала', ' '),\n",
       "  ('свою', ' '),\n",
       "  ('дошку', ' '),\n",
       "  ('і', ' '),\n",
       "  ('почала', ' '),\n",
       "  ('малювати', ' '),\n",
       "  ('ручкою', ' '),\n",
       "  ('та', ' '),\n",
       "  ('чорнилом', ','),\n",
       "  ('щоб', ' '),\n",
       "  ('проілюструвати', ' '),\n",
       "  ('журнальну', ' '),\n",
       "  ('історію', '.')],\n",
       " [('молоді', ' '),\n",
       "  ('художники', ' '),\n",
       "  ('повинні', ' '),\n",
       "  ('прокласти', ' '),\n",
       "  ('собі', ' '),\n",
       "  ('шлях', ' '),\n",
       "  ('до', ' '),\n",
       "  ('мистецтва', ','),\n",
       "  ('малюючи', ' '),\n",
       "  ('картинки', ' '),\n",
       "  ('для', ' '),\n",
       "  ('журнальних', ' '),\n",
       "  ('історій', ','),\n",
       "  ('які', ' '),\n",
       "  ('молоді', ' '),\n",
       "  ('автори', ' '),\n",
       "  ('пишуть', ','),\n",
       "  ('щоб', ' '),\n",
       "  ('прокласти', ' '),\n",
       "  ('собі', ' '),\n",
       "  ('шлях', ' '),\n",
       "  ('до', ' '),\n",
       "  ('літератури', '.')],\n",
       " [('поки', ' '),\n",
       "  ('сью', ' '),\n",
       "  ('замальовувала', ' '),\n",
       "  ('пару', ' '),\n",
       "  ('елегантних', ' '),\n",
       "  ('штанів', ' '),\n",
       "  ('для', ' '),\n",
       "  ('верхової', ' '),\n",
       "  ('їзди', ' '),\n",
       "  ('та', ' '),\n",
       "  ('монокль', ' '),\n",
       "  ('фігури', ' '),\n",
       "  ('героя', ','),\n",
       "  ('ковбоя', ' '),\n",
       "  ('айдахо', ','),\n",
       "  ('вона', ' '),\n",
       "  ('почула', ' '),\n",
       "  ('тихий', ' '),\n",
       "  ('звук', ','),\n",
       "  ('кілька', ' '),\n",
       "  ('разів', ' '),\n",
       "  ('повторений', '.')],\n",
       " [('вона', ' '), ('швидко', ' '), ('пішла', ' '), ('до', ' '), ('ліжка', '.')],\n",
       " [('очі', ' '),\n",
       "  ('джонсі', ' '),\n",
       "  ('були', ' '),\n",
       "  ('широко', ' '),\n",
       "  ('розплющені', '.')],\n",
       " [('вона', ' '),\n",
       "  ('дивилася', ' '),\n",
       "  ('у', ' '),\n",
       "  ('вікно', ' '),\n",
       "  ('і', ' '),\n",
       "  ('рахувала', ' '),\n",
       "  ('відлічуючи', ' '),\n",
       "  ('назад', '.')],\n",
       " [('дванадцять', ' '),\n",
       "  (',', ' '),\n",
       "  ('сказала', ' '),\n",
       "  ('вона', ','),\n",
       "  ('а', ' '),\n",
       "  ('трохи', ' '),\n",
       "  ('пізніше', ' '),\n",
       "  ('одинадцять', ' '),\n",
       "  ('а', ' '),\n",
       "  ('потім', ' '),\n",
       "  ('десять', ' '),\n",
       "  ('і', ' '),\n",
       "  (\"дев'ять\", ' '),\n",
       "  ('а', ' '),\n",
       "  ('потім', ' '),\n",
       "  ('вісім', ' '),\n",
       "  ('і', ' '),\n",
       "  ('сім', ' '),\n",
       "  (',', ' '),\n",
       "  ('майже', ' '),\n",
       "  ('разом', '.')],\n",
       " [('сью', ' '),\n",
       "  ('зазирливо', ' '),\n",
       "  ('виглядає', ' '),\n",
       "  ('у', ' '),\n",
       "  ('вікно', '.')],\n",
       " [('що', ' '), ('там', ' '), ('було', ' '), ('рахувати', '?')],\n",
       " [('видно', ' '),\n",
       "  ('було', ' '),\n",
       "  ('лише', ' '),\n",
       "  ('оголене', ' '),\n",
       "  ('та', ' '),\n",
       "  ('похмуре', ' '),\n",
       "  ('подвір’я', ','),\n",
       "  ('і', ' '),\n",
       "  ('глуху', ' '),\n",
       "  ('сторона', ' '),\n",
       "  ('цегляного', ' '),\n",
       "  ('будинку', ' '),\n",
       "  ('метрів', ' '),\n",
       "  ('за', ' '),\n",
       "  ('двадцять', '.')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29760"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319448\n",
      "3487\n"
     ]
    }
   ],
   "source": [
    "# split data into training and validation set in the ratio 90:10\n",
    "train_set, test_set = train_test_split(data, train_size=0.9, test_size=0.009, random_state=101)\n",
    "\n",
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('пишаюся', ','), ('що', ' '), ('тобі', ' '), ('вдається', ' '), ('і', ' ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some tagged words.\n",
    "train_tagged_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'?', '!', ',', ' ', '.'}\n"
     ]
    }
   ],
   "source": [
    "#use set datatype to check how many unique tags are present in training data\n",
    "tags = {tag for word, tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)\n",
    "\n",
    "# check total words in vocabulary\n",
    "vocab = {word for word, tag in train_tagged_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00756501 0.0108747  0.09598108 0.8600473  0.02553191]\n",
      " [0.00513611 0.01386749 0.08577298 0.86748844 0.02773498]\n",
      " [0.00314518 0.00539969 0.08219216 0.8954854  0.01377755]\n",
      " [0.00713678 0.00561741 0.11805072 0.7934702  0.07572489]\n",
      " [0.0062506  0.01202039 0.09948072 0.8529666  0.02923358]]\n"
     ]
    }
   ],
   "source": [
    "# compute Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "#now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "\n",
    "\n",
    "    return (count_w_given_tag, count_tag)\n",
    "\n",
    "\n",
    "# compute  Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)\n",
    "\n",
    "# creating t x t transition matrix of tags, t= no of tags\n",
    "# Matrix(i, j) represents P(jth tag after the ith tag)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "\n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>!</th>\n",
       "      <th>,</th>\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>0.095981</td>\n",
       "      <td>0.860047</td>\n",
       "      <td>0.025532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.085773</td>\n",
       "      <td>0.867488</td>\n",
       "      <td>0.027735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.895485</td>\n",
       "      <td>0.013778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.118051</td>\n",
       "      <td>0.793470</td>\n",
       "      <td>0.075725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>0.099481</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.029234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ?         !         ,                   .\n",
       "?  0.007565  0.010875  0.095981  0.860047  0.025532\n",
       "!  0.005136  0.013867  0.085773  0.867488  0.027735\n",
       ",  0.003145  0.005400  0.082192  0.895485  0.013778\n",
       "   0.007137  0.005617  0.118051  0.793470  0.075725\n",
       ".  0.006251  0.012020  0.099481  0.852967  0.029234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "# the table is same as the transition table shown in section 3 of article\n",
    "tags_df = pd.DataFrame(tags_matrix, columns=list(tags), index=list(tags))\n",
    "display(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def Viterbi(words, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    print(T)\n",
    "    for key, word in enumerate(tqdm(words)):\n",
    "        # initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag] + tags_df.loc['?', tag] + tags_df.loc['!', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "            # compute emission and state probabilities\n",
    "            count_word_tag, count_tag = word_given_tag(words[key], tag)\n",
    "            emission_p = count_word_tag / count_tag\n",
    "#             emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', '!', ',', ' ', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:18<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.708982706069946\n",
      "Viterbi Algorithm Accuracy:  79.36507936507937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    "\n",
    "# choose random 10 numbers\n",
    "rndom = [random.randint(1, len(test_set)) for x in range(10)]\n",
    "\n",
    "# list of 10 sents on which we test the model\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "\n",
    "# Here We will only test 10 sentences to check the accuracy\n",
    "# as testing the whole training set takes huge amount of time\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('у', ' '),\n",
       " ('статті', ' '),\n",
       " ('NUM', ' '),\n",
       " ('закону', ' '),\n",
       " ('україни', ' '),\n",
       " ('про', ' '),\n",
       " ('електронний', ' '),\n",
       " ('цифровий', '?'),\n",
       " ('підпис', ' '),\n",
       " ('сказано', ' '),\n",
       " ('що', ' '),\n",
       " ('“', ' '),\n",
       " ('електронний', ' '),\n",
       " ('підпис', ' '),\n",
       " ('не', ' '),\n",
       " ('може', ' '),\n",
       " ('бути', ' '),\n",
       " ('визнаний', ' '),\n",
       " ('недійсним', '?'),\n",
       " ('лише', ' '),\n",
       " ('через', ' '),\n",
       " ('те', ','),\n",
       " ('що', ' '),\n",
       " ('він', ' '),\n",
       " ('має', ' '),\n",
       " ('електронну', ' '),\n",
       " ('форму', ' '),\n",
       " ('або', ' '),\n",
       " ('не', ' '),\n",
       " ('ґрунтується', ' '),\n",
       " ('на', ' '),\n",
       " ('посиленому', '?'),\n",
       " ('сертифікаті', '?'),\n",
       " ('ключа', ' '),\n",
       " ('”', ' '),\n",
       " ('а', ' '),\n",
       " ('у', ' '),\n",
       " ('статті', ' '),\n",
       " ('NUM', ' '),\n",
       " ('що', ' '),\n",
       " ('“', ' '),\n",
       " ('юридичні', '?'),\n",
       " ('та', ' '),\n",
       " ('фізичні', ' '),\n",
       " ('особи', ' '),\n",
       " ('можуть', ' '),\n",
       " ('…', ' '),\n",
       " ('використовувати', ' '),\n",
       " ('електронний', ' '),\n",
       " ('цифровий', '?'),\n",
       " ('підпис', ' '),\n",
       " ('без', ' '),\n",
       " ('сертифіката', '?'),\n",
       " ('ключа', ' '),\n",
       " ('”', ' '),\n",
       " ('розум', ' '),\n",
       " ('у', ' '),\n",
       " ('чому', ' '),\n",
       " ('проблема', ' '),\n",
       " ('сайтів', ' '),\n",
       " ('підприємців', ' '),\n",
       " ('власників', ' '),\n",
       " ('крамниць', ' '),\n",
       " ('ресторанів', '?'),\n",
       " ('кафетеріїв', '?'),\n",
       " ('інших', ' '),\n",
       " ('фопів', ','),\n",
       " ('які', ' '),\n",
       " ('надають', ' '),\n",
       " ('найрізноманітніші', ' '),\n",
       " ('послуги', ' '),\n",
       " ('у', ' '),\n",
       " ('вагон', ' '),\n",
       " ('влітає', ' '),\n",
       " ('вологий', ','),\n",
       " ('холодний', ' '),\n",
       " ('вітер', ' '),\n",
       " ('розгляньмо', ' '),\n",
       " ('спочатку', ' '),\n",
       " ('декілька', ' '),\n",
       " ('прикладів', ' '),\n",
       " ('як', ' '),\n",
       " ('коаліційні', ' '),\n",
       " ('ігри', ' '),\n",
       " ('виникають', ' '),\n",
       " ('у', ' '),\n",
       " ('різних', ' '),\n",
       " ('ситуаціях', ','),\n",
       " ('цих', ' '),\n",
       " ('слів', ' '),\n",
       " ('маргарита', ' '),\n",
       " ('не', ' '),\n",
       " ('витримала', ' '),\n",
       " ('і', ' '),\n",
       " ('знову', ' '),\n",
       " ('заплакала', ' '),\n",
       " ('евері', ' '),\n",
       " ('найт', ' '),\n",
       " ('сидів', ' '),\n",
       " ('занурений', ' '),\n",
       " ('у', ' '),\n",
       " ('свої', ' '),\n",
       " ('думки', ' '),\n",
       " ('певний', ' '),\n",
       " ('час', ' '),\n",
       " ('першим', ' '),\n",
       " ('заговорив', ' '),\n",
       " ('арештант', ','),\n",
       " ('освіта', ' '),\n",
       " ('сьогодні', ' '),\n",
       " ('це', ' '),\n",
       " ('щось', ' '),\n",
       " ('більше', ' '),\n",
       " ('ніж', ' '),\n",
       " ('просто', ' '),\n",
       " ('передача', ' '),\n",
       " ('знань', ' '),\n",
       " ('степан', ' '),\n",
       " ('намацав', ' '),\n",
       " ('на', ' '),\n",
       " ('стільці', ' '),\n",
       " ('поряд', ' '),\n",
       " ('із', ' '),\n",
       " ('ліжком', ','),\n",
       " ('штани', ' '),\n",
       " ('шепнув', ' ')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_sign(predicted_seq, test_seq, punctuation_sign):\n",
    "    test_pos = set([i for i, (_, second) in enumerate(test_seq) if second == punctuation_sign])\n",
    "    predicted_pos = set([i for i, (_, second) in enumerate(predicted_seq) if second == punctuation_sign])\n",
    "    \n",
    "    # how many times was a punctuation sign restored correctly\n",
    "    true_positives = len(test_pos & predicted_pos)\n",
    "    \n",
    "    # how many times wasn't a punctuation sign restored when it should habe been\n",
    "    false_negatives = len(test_pos - predicted_pos)\n",
    "    \n",
    "    # how many times was a punctuation sign restored when it shouldn't have been there\n",
    "    false_positives = len(predicted_pos - test_pos)\n",
    "    \n",
    "    no_test_pos = set([i for i, (_, second) in enumerate(test_seq) if second != punctuation_sign])\n",
    "    no_predicted_pos = set([i for i, (_, second) in enumerate(predicted_seq) if second != punctuation_sign])\n",
    "    true_negatives = len(no_test_pos & no_predicted_pos)\n",
    "    \n",
    "    return true_positives, false_positives, false_negatives, true_negatives\n",
    "\n",
    "\n",
    "def standard_tests(true_positives, false_positives, false_negatives, true_negatives):\n",
    "    accuracy = (true_positives + true_negatives) / \\\n",
    "        (true_positives + true_negatives + false_positives + false_negatives) \\\n",
    "        if (true_positives + true_negatives + false_positives + false_negatives) > 0 else np.nan\n",
    "    precision = true_positives / (true_positives + false_positives) \\\n",
    "        if (true_positives + false_positives) > 0 else np.nan\n",
    "    recall = true_positives / (true_positives + false_negatives) \\\n",
    "        if (true_positives + false_negatives) > 0 else np.nan\n",
    "    f_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else np.nan\n",
    "    \n",
    "    return f\"{accuracy:.3f}\", f\"{precision:.3f}\", f\"{recall:.3f}\", f\"{f_score:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation      Accuracy  Precision    Recall    F-score  \n",
      "?                0.921     0.000        0.000     nan      \n",
      "!                1.000     nan          nan       nan      \n",
      ",                0.905     0.333        0.200     0.250    \n",
      "                 0.817     0.883        0.907     0.895    \n",
      ".                0.944     nan          0.000     nan      \n",
      "Overall          0.917     0.794        0.794     0.794    \n"
     ]
    }
   ],
   "source": [
    "def evaluate(predicted_seq, test_seq):\n",
    "    tp, fp, fn, tn = 0,0,0,0\n",
    "    print(\"{:<16} {:<9} {:<12} {:<9} {:<9}\".format(\"Punctuation\", \"Accuracy\", \"Precision\", \"Recall\", \"F-score\"))\n",
    "    for tag in tags:\n",
    "        true_positives, false_positives, false_negatives, true_negatives = \\\n",
    "            measure_sign(predicted_seq, test_seq, tag)\n",
    "        tp += true_positives\n",
    "        fp += false_positives\n",
    "        fn += false_negatives\n",
    "        tn += true_negatives\n",
    "        accuracy, precision, recall, f_score = \\\n",
    "            standard_tests(true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print(\"{:<16} {:<9} {:<12} {:<9} {:<9}\".format(tag, accuracy, precision, recall, f_score))\n",
    "\n",
    "    accuracy, precision, recall, f_score = standard_tests(tp, fp, fn, tn)\n",
    "    print(\"{:<16} {:<9} {:<12} {:<9} {:<9}\".format(\"Overall\", accuracy, precision, recall, f_score))\n",
    "\n",
    "evaluate(tagged_seq, test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Code to test all the test sentences\n",
    "# (takes alot of time to run s0 we won't run it here)\n",
    "# tagging the test sentences()\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "test_untagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "\n",
    "\n",
    "print('Starting testing')\n",
    "# start = time.time()\n",
    "tagged_seq = Viterbi(test_untagged_words)\n",
    "# end = time.time()\n",
    "# difference = end-start\n",
    "\n",
    "# print(\"Time taken in seconds: \", difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_untagged_words) if i == j]\n",
    "\n",
    "accuracy = len(check) / len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
